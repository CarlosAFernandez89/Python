{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:26:49.015838900Z",
     "start_time": "2023-11-08T19:26:49.012551300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.theta = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Add the bias term\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        # Compute the matrix A (X^T X) and the vector b (X^T y)\n",
    "        A = X_b.T.dot(X_b)\n",
    "        b = X_b.T.dot(y)\n",
    "        # Solve the linear equation A * theta = b for theta\n",
    "        self.theta = np.linalg.solve(A, b)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Add bias term \n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        return X_b.dot(self.theta)\n",
    "\n",
    "\n",
    "class LogisticRegressionGD:\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000, method=\"gd\", tol=1e-4):\n",
    "        self.duration = None\n",
    "        self.total_iterations = None\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.method = method\n",
    "        self.tol = tol  # tolerance for stopping condition\n",
    "        self.theta = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def cost_function(self, X, y):\n",
    "        m = len(y)\n",
    "        predictions = self.sigmoid(X.dot(self.theta))\n",
    "        cost = -1/m * (y.T.dot(np.log(predictions)) + (1 - y).T.dot(np.log(1 - predictions)))\n",
    "        return cost[0][0]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probabilities = self.sigmoid(X.dot(self.theta))\n",
    "        return probabilities\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        self.theta = np.zeros((n, 1))\n",
    "        prev_cost = float('inf')\n",
    "\n",
    "        # Initialize the total iterations counter\n",
    "        total_iterations = 0\n",
    "\n",
    "        # Record the start time\n",
    "        start_time = time.time()\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            if self.method == \"gd\":  # Gradient Descent\n",
    "                gradient = X.T.dot(self.sigmoid(X.dot(self.theta)) - y) / m\n",
    "                self.theta -= self.learning_rate * gradient\n",
    "                total_iterations += 1\n",
    "            elif self.method == \"sgd\":  # Stochastic Gradient Descent\n",
    "                for i in range(m):\n",
    "                    random_index = np.random.randint(m)\n",
    "                    xi = X[random_index:random_index+1]\n",
    "                    yi = y[random_index:random_index+1]\n",
    "                    gradient = xi.T.dot(self.sigmoid(xi.dot(self.theta)) - yi)\n",
    "                    self.theta -= self.learning_rate * gradient\n",
    "                    total_iterations += 1\n",
    "\n",
    "            # Calculate cost for current epoch\n",
    "            current_cost = self.cost_function(X, y)\n",
    "\n",
    "            # Check stopping condition\n",
    "            if abs(prev_cost - current_cost) < self.tol:\n",
    "                # Calculate the time taken\n",
    "                duration = time.time() - start_time\n",
    "                print(f\"{self.method.title()} converged after {total_iterations} iterations in {duration:.4f} seconds. Stopping.\")\n",
    "                break\n",
    "\n",
    "            prev_cost = current_cost\n",
    "\n",
    "        # If the loop finishes without convergence\n",
    "        if self.method == \"gd\" and epoch == self.epochs - 1:\n",
    "            duration = time.time() - start_time\n",
    "            print(f\"Gradient Descent completed {self.epochs} epochs in {duration:.4f} seconds.\")\n",
    "\n",
    "        if self.method == \"sgd\" and epoch == self.epochs - 1:\n",
    "            duration = time.time() - start_time\n",
    "            print(f\"Stochastic Gradient Descent completed {total_iterations} iterations in {duration:.4f} seconds.\")\n",
    "\n",
    "        # Store the total iterations and duration in the class instance for later reference\n",
    "        self.total_iterations = total_iterations\n",
    "        self.duration = duration\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the Training tab\n",
    "training_data = pd.read_excel('Project3.xlsx', sheet_name='Training', engine='openpyxl')\n",
    "\n",
    "# Load the data from the Predict tab\n",
    "predict_data = pd.read_excel('Project3.xlsx', sheet_name='Predict', engine='openpyxl')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:26:49.055357700Z",
     "start_time": "2023-11-08T19:26:49.016832100Z"
    }
   },
   "id": "c3e4206558a25c06"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight vector (theta): [[79.835     ]\n",
      " [ 4.17743519]\n",
      " [ 3.03946093]\n",
      " [ 6.71839328]]\n"
     ]
    }
   ],
   "source": [
    "#Step 1(a)\n",
    "\n",
    "X_train = training_data[['Midterm', 'Homework', 'Quiz']].values\n",
    "y_train = training_data['Course Grade'].values.reshape(-1, 1)\n",
    "\n",
    "# Normalize the features to improve convergence\n",
    "X_train_mean = np.mean(X_train, axis=0)\n",
    "X_train_std = np.std(X_train, axis=0)\n",
    "X_train = (X_train - X_train_mean) / X_train_std\n",
    "\n",
    "X_train_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "\n",
    "# Define the LinearRegression class and fit the model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Display the weight vector\n",
    "print(\"Weight vector (theta):\", lin_reg.theta)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:26:49.067051400Z",
     "start_time": "2023-11-08T19:26:49.055357700Z"
    }
   },
   "id": "4726f2ca7c528620"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Midterm  Homework  Quiz  Estimated Course Grade\n",
      "0        49        79    71               65.243032\n",
      "1        56        21    46               48.356620\n",
      "2        58       100    79               74.881560\n",
      "3        61        82    58               64.225981\n",
      "4        62        90    62               67.470391\n",
      "5        66        99    75               75.770889\n",
      "6        71        73    65               69.362745\n",
      "7        73        87    80               78.570618\n",
      "8        73        97    73               77.029189\n",
      "9        74        73    77               75.563111\n",
      "10       74        85    66               72.594112\n",
      "11       74       100    87               83.842523\n",
      "12       78        79    56               68.785211\n",
      "13       80        72    71               74.901825\n",
      "14       80        82    90               84.553235\n",
      "15       81        56    60               68.155962\n",
      "16       81        80    78               79.437717\n",
      "17       82       100    79               83.157079\n",
      "18       83        80    56               70.656480\n",
      "19       83        96    64               76.455675\n",
      "20       84        98    85               86.135263\n",
      "21       84       100    77               82.985718\n",
      "22       85        93    75               81.439125\n",
      "23       85        99    69               79.739379\n",
      "24       86        95    77               82.939331\n",
      "25       86       100    85               87.119295\n",
      "26       87        97    75               82.717562\n",
      "27       87        98    89               88.891678\n",
      "28       87        99    85               87.316906\n",
      "29       87        99    81               85.594931\n",
      "30       88        99    73               82.495794\n",
      "31       89        82    37               64.840383\n",
      "32       89        82    81               83.782110\n",
      "33       89        99    79               85.423570\n",
      "34       90       100    90               90.651018\n",
      "35       91        67    84               83.555177\n",
      "36       91       100    79               86.260399\n",
      "37       92        99    85               89.040972\n",
      "38       93        97    71               83.064467\n",
      "39       94        99    89               91.452574\n",
      "40       95        98    85               89.928210\n",
      "41       95        99    69               83.187512\n",
      "42       97        80    79               85.385224\n",
      "43       97        99    92               93.778496\n",
      "44       97       100    87               91.773229\n",
      "45       98       100    81               89.535080\n",
      "46       99       100   100               98.059275\n",
      "47      100        76    90               90.566284\n",
      "48      100        94    94               94.937909\n",
      "49      100       100    94               95.821126\n"
     ]
    }
   ],
   "source": [
    "#Step 1(b)\n",
    "\n",
    "X_predict = predict_data[['Midterm', 'Homework', 'Quiz']].values\n",
    "\n",
    "# Normalize using the mean and std from the training data\n",
    "X_predict = (X_predict - X_train_mean) / X_train_std\n",
    "\n",
    "X_predict_bias = np.c_[np.ones((X_predict.shape[0], 1)), X_predict]\n",
    "\n",
    "# Use the model to make predictions\n",
    "y_pred = lin_reg.predict(X_predict)\n",
    "\n",
    "# Add predictions to the predict_data dataframe\n",
    "predict_data['Estimated Course Grade'] = y_pred.flatten()\n",
    "predict_data_sgd = predict_data\n",
    "\n",
    "# Display the predictions\n",
    "print(predict_data[['Midterm', 'Homework', 'Quiz', 'Estimated Course Grade']])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:26:49.067051400Z",
     "start_time": "2023-11-08T19:26:49.062187600Z"
    }
   },
   "id": "ba5dffb0393eef70"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Midterm  Homework  Quiz  Course Grade\n",
      "0         37        23    41             0\n",
      "1         38       100    54             0\n",
      "2         40        16    24             0\n",
      "3         44        93    46             0\n",
      "4         48        96    39             0\n",
      "..       ...       ...   ...           ...\n",
      "395      100        70    84             1\n",
      "396      100        81    94             1\n",
      "397      100        96   100             1\n",
      "398      100        99    93             1\n",
      "399      100       100   100             1\n",
      "\n",
      "[400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 2(a)\n",
    "\n",
    "# Convert course grades to binary labels\n",
    "training_data['Course Grade'] = training_data['Course Grade'].apply(lambda x: 0 if x < 70 else 1)\n",
    "\n",
    "y_train = training_data['Course Grade'].values.reshape(-1, 1)\n",
    "\n",
    "# Display the modified labels\n",
    "print(training_data[['Midterm', 'Homework', 'Quiz', 'Course Grade']])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:26:49.079954400Z",
     "start_time": "2023-11-08T19:26:49.069530900Z"
    }
   },
   "id": "37a6289e02278e87"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sgd converged after 48800 iterations in 0.6354 seconds. Stopping.\n",
      "[[2.86754413]\n",
      " [0.85101467]\n",
      " [0.89257833]\n",
      " [1.22435293]]\n",
      "Gd converged after 1310 iterations in 0.0428 seconds. Stopping.\n",
      "[[0.38972032]\n",
      " [0.16213183]\n",
      " [0.17888972]\n",
      " [0.22566503]]\n"
     ]
    }
   ],
   "source": [
    "# Step 2(b)\n",
    "\n",
    "\n",
    "# Create an instance of LogisticRegressionGD (SGD) and fit the training data\n",
    "log_reg_sgd = LogisticRegressionGD(learning_rate=0.001, epochs=10000, method=\"sgd\")\n",
    "log_reg_sgd.fit(X_train_bias, y_train)\n",
    "print(log_reg_sgd.theta)\n",
    "\n",
    "# Create an instance of LogisticRegressionGD (GD) and fit the training data\n",
    "log_reg = LogisticRegressionGD(learning_rate=0.001, epochs=10000, method=\"gd\")\n",
    "log_reg.fit(X_train_bias, y_train)\n",
    "print(log_reg.theta)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:26:49.762471100Z",
     "start_time": "2023-11-08T19:26:49.074003200Z"
    }
   },
   "id": "eab0dd6365f1bc98"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Descent Predicted Data: \n",
      "    Midterm  Homework  Quiz  Probability of Passing\n",
      "0        49        79    71                0.484883\n",
      "1        56        21    46                0.017339\n",
      "2        58       100    79                0.891593\n",
      "3        61        82    58                0.473087\n",
      "4        62        90    62                0.650701\n",
      "5        66        99    75                0.909869\n",
      "6        71        73    65                0.680224\n",
      "7        73        87    80                0.935672\n",
      "8        73        97    73                0.928268\n",
      "9        74        73    77                0.870678\n",
      "10       74        85    66                0.826744\n",
      "11       74       100    87                0.979339\n",
      "12       78        79    56                0.689933\n",
      "13       80        72    71                0.859904\n",
      "14       80        82    90                0.976737\n",
      "15       81        56    60                0.581785\n",
      "16       81        80    78                0.941570\n",
      "17       82       100    79                0.977968\n",
      "18       83        80    56                0.767501\n",
      "19       83        96    64                0.925085\n",
      "20       84        98    85                0.986845\n",
      "21       84       100    77                0.977612\n",
      "22       85        93    75                0.967306\n",
      "23       85        99    69                0.959920\n",
      "24       86        95    77                0.975895\n",
      "25       86       100    85                0.989488\n",
      "26       87        97    75                0.975890\n",
      "27       87        98    89                0.992173\n",
      "28       87        99    85                0.989765\n",
      "29       87        99    81                0.986045\n",
      "30       88        99    73                0.975885\n",
      "31       89        82    37                0.552698\n",
      "32       89        82    81                0.974998\n",
      "33       89        99    79                0.985818\n",
      "34       90       100    90                0.994611\n",
      "35       91        67    84                0.967420\n",
      "36       91       100    79                0.988170\n",
      "37       92        99    85                0.992775\n",
      "38       93        97    71                0.978297\n",
      "39       94        99    89                0.995401\n",
      "40       95        98    85                0.993882\n",
      "41       95        99    69                0.979735\n",
      "42       97        80    79                0.981695\n",
      "43       97        99    92                0.997051\n",
      "44       97       100    87                0.995824\n",
      "45       98       100    81                0.993780\n",
      "46       99       100   100                0.998688\n",
      "47      100        76    90                0.992482\n",
      "48      100        94    94                0.997464\n",
      "49      100       100    94                0.998043\n",
      "\n",
      "Stochastic Gradient Descent Predicted Data: \n",
      "    Midterm  Homework  Quiz  Probability of Passing\n",
      "0        49        79    71                0.484883\n",
      "1        56        21    46                0.017339\n",
      "2        58       100    79                0.891593\n",
      "3        61        82    58                0.473087\n",
      "4        62        90    62                0.650701\n",
      "5        66        99    75                0.909869\n",
      "6        71        73    65                0.680224\n",
      "7        73        87    80                0.935672\n",
      "8        73        97    73                0.928268\n",
      "9        74        73    77                0.870678\n",
      "10       74        85    66                0.826744\n",
      "11       74       100    87                0.979339\n",
      "12       78        79    56                0.689933\n",
      "13       80        72    71                0.859904\n",
      "14       80        82    90                0.976737\n",
      "15       81        56    60                0.581785\n",
      "16       81        80    78                0.941570\n",
      "17       82       100    79                0.977968\n",
      "18       83        80    56                0.767501\n",
      "19       83        96    64                0.925085\n",
      "20       84        98    85                0.986845\n",
      "21       84       100    77                0.977612\n",
      "22       85        93    75                0.967306\n",
      "23       85        99    69                0.959920\n",
      "24       86        95    77                0.975895\n",
      "25       86       100    85                0.989488\n",
      "26       87        97    75                0.975890\n",
      "27       87        98    89                0.992173\n",
      "28       87        99    85                0.989765\n",
      "29       87        99    81                0.986045\n",
      "30       88        99    73                0.975885\n",
      "31       89        82    37                0.552698\n",
      "32       89        82    81                0.974998\n",
      "33       89        99    79                0.985818\n",
      "34       90       100    90                0.994611\n",
      "35       91        67    84                0.967420\n",
      "36       91       100    79                0.988170\n",
      "37       92        99    85                0.992775\n",
      "38       93        97    71                0.978297\n",
      "39       94        99    89                0.995401\n",
      "40       95        98    85                0.993882\n",
      "41       95        99    69                0.979735\n",
      "42       97        80    79                0.981695\n",
      "43       97        99    92                0.997051\n",
      "44       97       100    87                0.995824\n",
      "45       98       100    81                0.993780\n",
      "46       99       100   100                0.998688\n",
      "47      100        76    90                0.992482\n",
      "48      100        94    94                0.997464\n",
      "49      100       100    94                0.998043\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to estimate the probability of passing\n",
    "probabilities_passing = log_reg.predict_proba(X_predict_bias)\n",
    "probabilities_passing_sgd = log_reg_sgd.predict_proba(X_predict_bias)\n",
    "\n",
    "\n",
    "# Add probabilities to the predict_data dataframe\n",
    "predict_data['Probability of Passing'] = probabilities_passing\n",
    "predict_data_sgd['Probability of Passing'] = probabilities_passing_sgd\n",
    "\n",
    "\n",
    "# Display the data along with the predicted probabilities\n",
    "print(f\"\\nGradient Descent Predicted Data: \")\n",
    "print(predict_data[['Midterm', 'Homework', 'Quiz', 'Probability of Passing']])\n",
    "print(f\"\\nStochastic Gradient Descent Predicted Data: \")\n",
    "print(predict_data_sgd[['Midterm', 'Homework', 'Quiz', 'Probability of Passing']])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:26:49.763969400Z",
     "start_time": "2023-11-08T19:26:49.757182700Z"
    }
   },
   "id": "aae2f43f55c75cca"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(predict_data.compare(predict_data_sgd))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:26:49.771335500Z",
     "start_time": "2023-11-08T19:26:49.764465800Z"
    }
   },
   "id": "3f1b2c2ad93751e1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
